{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(os.path.join(os.getcwd(), \"nltk_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(f_type,doc_text):    ### Regex function for finding the beginning and ending of 10-Q and 10-K filings\n",
    "    start_mda = -1\n",
    "    end_mda = -1\n",
    "    if f_type == 'EX-13.3':\n",
    "        print('Ex')\n",
    "        start_mda = 0\n",
    "        end_mda = len(doc_text)\n",
    "        return start_mda,end_mda\n",
    "    \n",
    "    if f_type == '10-K':\n",
    "        regex = re.compile(r'I[tT][eE][mM] 7\\.\\s*M[aA][nN][aA][gG][eE][mM][eE][nN][tT]')\n",
    "    elif f_type == '10-Q':\n",
    "        regex = re.compile(r'I[tT][eE][mM] 2\\.\\s*M[aA][nN][aA][gG][eE][mM][eE][nN][tT]')\n",
    "        \n",
    "    match = regex.finditer(doc_text)\n",
    "\n",
    "    for m in match:\n",
    "        start_mda = m.span()[0]\n",
    "        break\n",
    "\n",
    "    if f_type == '10-K':\n",
    "        regex = re.compile(r'I[tT][eE][mM] 8\\.\\s*F[iI][nN][aA][nN][cC][iI][aA][lL]')\n",
    "    elif f_type == '10-Q':\n",
    "        regex = re.compile(r'I[tT][eE][mM] 3\\.\\s*Q[uU][aA][nN][tT][iI][tT][aA][tT][iI][vV][eE]')\n",
    "        \n",
    "    match = regex.finditer(doc_text)\n",
    "    for m in match:\n",
    "        end_mda = m.span()[0]\n",
    "        break\n",
    "    \n",
    "    if (f_type == '10-Q') and (end_mda == -1):   ### For old 10-Qs, it is a different format\n",
    "        regex = re.compile(r'I[tT][eE][mM] 1\\.\\s*L[eE][gG][aA][lL]')\n",
    "    \n",
    "    match = regex.finditer(doc_text)\n",
    "    for m in match:\n",
    "        end_mda = m.span()[0]\n",
    "        break\n",
    "        \n",
    "        \n",
    "    print(start_mda,\",\",end_mda)\n",
    "       \n",
    "    return start_mda,end_mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mda(filing_type, filing_link):    ### Returns a clean text of MDA based on the filing type and its link\n",
    "    final_doc = requests.get(filing_link)\n",
    "    soup_ob = BeautifulSoup(final_doc.content,'html.parser')\n",
    "\n",
    "    for table in soup_ob.find_all(\"table\"): \n",
    "        table.decompose()                     ### Removing all tables from the text\n",
    "\n",
    "    #soup_ob.get_text()                        ### Fetching just the textual data\n",
    "\n",
    "    final_text = soup_ob.get_text().replace('\\n',' ').replace('\\t',' ').replace('\\xa0',' ') ### get_text. remove string operations\n",
    "\n",
    "    start , end  = get_index(filing_type,final_text)\n",
    "    final_text = final_text[start + 8:end]                    ### Fetching MD&A of 10-K filings\n",
    "\n",
    "    final_text = re.sub(r'\\([^()]*\\)', '', final_text.lower()) ### Removing everything between two brackets since it is mostly unnecessary\n",
    "    \n",
    "    if filing_type == '10-K':                            ### Removing Page numbers from filings\n",
    "        final_text = re.sub(r'[0-9][0-9]\\s*part ii item [0-9]', '', final_text)\n",
    "    elif filing_type == '10-Q':\n",
    "        final_text = re.sub(r'[0-9][0-9]\\s*part i item [0-9]', '', final_text)\n",
    "        \n",
    "    final_text = re.sub(r':', '.', final_text)  ### ':' Present at the end of sentences before presenting tables. \n",
    "    final_text = re.sub(r',', ' ', final_text)  ### TODO : Remove all punctuations, numbers and special characeters\n",
    "    # Normalize it\n",
    "    #final_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", final_text.lower())\n",
    "    \n",
    "    return final_text,start,end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(element): ### Helper function\n",
    "    try:\n",
    "        float(element)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching the page containing the links for previous 100 10-K and 10-Q filings of the company based on CIK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request Successful\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000789019&type=10&dateb=&owner=exclude&start=&output=&count=100\n"
     ]
    }
   ],
   "source": [
    "endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "\n",
    "# define our parameters dictionary\n",
    "param_dict = {'action':'getcompany',\n",
    "              'CIK':'0000789019',            ### CIK details of the company\n",
    "              'type':'10',                   ### 10 in the search bar resulting in all 10 related filings\n",
    "              'dateb':'',\n",
    "              'owner':'exclude',\n",
    "              'start':'',\n",
    "              'output':'',\n",
    "              'count':'100'}                ### Return upto 100(max limit) SEC filings\n",
    "\n",
    "# request the url, and then parse the response.\n",
    "response = requests.get(url = endpoint, params = param_dict)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Let the user know it was successful.\n",
    "print('Request Successful')\n",
    "print(response.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going through the response of the table and storing the required links of SEC filings in a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table',summary = 'Results')                   ### Results Table\n",
    "\n",
    "filing_data = []\n",
    "\n",
    "for i,j in enumerate(table.find_all('tr')):                     ### For each row in table\n",
    "    if i is 0:   ### Header row\n",
    "        continue                   \n",
    "    \n",
    "    row_list = j.find_all('td')        ### Find all columns in the row\n",
    "    \n",
    "    filing_type = row_list[0].get_text()    ### get the text in the first column(filing name/type)\n",
    "    \n",
    "    if not (filing_type == '10-Q' or filing_type == '10-K'): #get only 10Q and 10K. No amendments (10-Q/A)\n",
    "        continue\n",
    "    \n",
    "    filing_date = row_list[3].get_text()    ### Get the filing date listed in the 4th column\n",
    "    \n",
    "    files_link = r'https://www.sec.gov/' + row_list[1].a.get('href')    ### Link of the filings filed on the date\n",
    "    \n",
    "    next_page = requests.get(files_link)        ### Link for the page storing all the filings\n",
    "    contents = next_page.content       \n",
    "    soup2 = BeautifulSoup(contents, 'html.parser')    ### New soup object to parse the next page\n",
    "    \n",
    "    table2 = soup2.find('table',summary = 'Document Format Files')     ### Table storing all the uploaded filings\n",
    "    \n",
    "    flag = 0 \n",
    "    for p,q in enumerate(table2.find_all('tr')):      ### For all the rows in this table\n",
    "        \n",
    "        if p is 0:    ### Header row\n",
    "            continue\n",
    "        row_list2 = q.find_all('td')     ### For all columns in the row\n",
    "        \n",
    "        doc_string = row_list2[2].get_text()     ### Name of the uploaded doc\n",
    "        type_string = row_list2[3].get_text()   ### type of filing\n",
    "        \n",
    "        if type_string == '10-Q' or type_string == '10-K': \n",
    "            if doc_string == '':\n",
    "                continue #next row\n",
    "            else:\n",
    "                filing_link = r'https://www.sec.gov/' + row_list2[2].a.get('href')\n",
    "                flag = 1\n",
    "                \n",
    "        if type_string == 'EX-13.3':\n",
    "            if doc_string == '':\n",
    "                break\n",
    "            else:\n",
    "                filing_link = r'https://www.sec.gov/' + row_list2[2].a.get('href')\n",
    "                flag = 1\n",
    "                filing_type = 'EX-13.3'\n",
    "                print(type_string)\n",
    "                break\n",
    "\n",
    "    if flag == 0:   ### If no link is found in any of the tables, take the full text of the filing. \n",
    "        filing_link = files_link.split('-index')[0] + '.txt'\n",
    "        #print(r'https://www.sec.gov/' + row_list2[2].a.get('href'))\n",
    "    \n",
    "    filing_link = re.sub(r'ix\\?doc=/','',filing_link)   ### remove the iXBRL format for the latest filings\n",
    "    filing_data.append([filing_type,filing_link,filing_date])\n",
    "    print(filing_link)\n",
    "    \n",
    "data = pd.DataFrame(filing_data,columns = ['Filing_type','Filing_link','Filing_date'])   ### Create a data frame of the table\n",
    "data['Sentences'] = ''\n",
    "data['Words'] = ''\n",
    "\n",
    "data['Mda_index']=''\n",
    "for i in range(len(data)):\n",
    "    mda,start,end = get_mda(data['Filing_type'][i],data['Filing_link'][i])  ### Get the MDA section\n",
    "    #print(mda)\n",
    "\n",
    "    sent_mda = sent_tokenize(mda)                          ### list of all sentences in the MDA\n",
    "\n",
    "    sent_mda = [x.strip() for x in sent_mda if len(x.strip()) > 15]   ### Keep sentences which are atleast 15 characters long\n",
    "\n",
    "    words_mda = word_tokenize(mda)                     ### Fetching just the words from MDA\n",
    "\n",
    "    words_mda = [x for x in words_mda if not is_float(x)]\n",
    "    words_mda = [(WordNetLemmatizer().lemmatize(x)) for x in words_mda if x not in stop_words and len(x) > 2]\n",
    "\n",
    "    data['Sentences'][i] = sent_mda\n",
    "    data['Words'][i] = words_mda\n",
    "    data['Mda_index'][i] = (start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filing_type</th>\n",
       "      <th>Filing_link</th>\n",
       "      <th>Filing_date</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Words</th>\n",
       "      <th>Mda_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov//Archives/edgar/data/78901...</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>[management’s discussion and analysis of finan...</td>\n",
       "      <td>[management, discussion, analysis, financial, ...</td>\n",
       "      <td>(75041, 113497)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov//Archives/edgar/data/78901...</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>[management’s discussion and analysis of finan...</td>\n",
       "      <td>[management, discussion, analysis, financial, ...</td>\n",
       "      <td>(65214, 99158)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-K</td>\n",
       "      <td>https://www.sec.gov//Archives/edgar/data/78901...</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>[management’s discussion and analysis of finan...</td>\n",
       "      <td>[management, discussion, analysis, financial, ...</td>\n",
       "      <td>(111753, 161210)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov//Archives/edgar/data/78901...</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>[management’s discussion and analysis of finan...</td>\n",
       "      <td>[management, discussion, analysis, financial, ...</td>\n",
       "      <td>(51304, 93244)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filing_type                                        Filing_link Filing_date  \\\n",
       "1        10-Q  https://www.sec.gov//Archives/edgar/data/78901...  2020-01-29   \n",
       "2        10-Q  https://www.sec.gov//Archives/edgar/data/78901...  2019-10-23   \n",
       "3        10-K  https://www.sec.gov//Archives/edgar/data/78901...  2019-08-01   \n",
       "4        10-Q  https://www.sec.gov//Archives/edgar/data/78901...  2019-04-24   \n",
       "\n",
       "                                           Sentences  \\\n",
       "1  [management’s discussion and analysis of finan...   \n",
       "2  [management’s discussion and analysis of finan...   \n",
       "3  [management’s discussion and analysis of finan...   \n",
       "4  [management’s discussion and analysis of finan...   \n",
       "\n",
       "                                               Words         Mda_index  \n",
       "1  [management, discussion, analysis, financial, ...   (75041, 113497)  \n",
       "2  [management, discussion, analysis, financial, ...    (65214, 99158)  \n",
       "3  [management, discussion, analysis, financial, ...  (111753, 161210)  \n",
       "4  [management, discussion, analysis, financial, ...    (51304, 93244)  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.438176155090332\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "data_size = sys.getsizeof(data)\n",
    "\n",
    "print((data_size/1024)/1024)   ### Size in MB of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sent = SentimentIntensityAnalyzer()         ### Sentiment Analyzer used to find the sentiment from sentences\n",
    "\n",
    "#for x in sent_mda:    \n",
    "#    print(vader_sent.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
